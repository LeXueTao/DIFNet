{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
=======
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from data.vocab import Vocab\n",
    "import torch\n",
    "from data.utils import get_tokenizer\n",
    "from collections import Counter, OrderedDict\n",
    "import six\n",
    "from data.dataset import Dataset\n",
    "from itertools import chain\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RawField(object):\n",
    "    \"\"\" Defines a general datatype.\n",
    "\n",
    "    Every dataset consists of one or more types of data. For instance,\n",
    "    a machine translation dataset contains paired examples of text, while\n",
    "    an image captioning dataset contains images and texts.\n",
    "    Each of these types of data is represented by a RawField object.\n",
    "    An RawField object does not assume any property of the data type and\n",
    "    it holds parameters relating to how a datatype should be processed.\n",
    "\n",
    "    Attributes:\n",
    "        preprocessing: The Pipeline that will be applied to examples\n",
    "            using this field before creating an example.\n",
    "            Default: None.\n",
    "        postprocessing: A Pipeline that will be applied to a list of examples\n",
    "            using this field before assigning to a batch.\n",
    "            Function signature: (batch(list)) -> object\n",
    "            Default: None.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, preprocessing=None, postprocessing=None):\n",
    "        self.preprocessing = preprocessing\n",
    "        self.postprocessing = postprocessing\n",
    "\n",
    "    def preprocess(self, x):\n",
    "        \"\"\" Preprocess an example if the `preprocessing` Pipeline is provided. \"\"\"\n",
    "        if self.preprocessing is not None:\n",
    "            return self.preprocessing(x)\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def process(self, batch, *args, **kwargs):\n",
    "        \"\"\" Process a list of examples to create a batch.\n",
    "\n",
    "        Postprocess the batch with user-provided Pipeline.\n",
    "\n",
    "        Args:\n",
    "            batch (list(object)): A list of object from a batch of examples.\n",
    "        Returns:\n",
    "            object: Processed object given the input and custom\n",
    "                postprocessing Pipeline.\n",
    "        \"\"\"\n",
    "        if self.postprocessing is not None:\n",
    "            batch = self.postprocessing(batch)\n",
    "        return default_collate(batch)"
>>>>>>> e6e60c720fa90393db271e3e4afc07a0a59acfc5
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "aa = ['hello world!!!'] * 5"
=======
    "class TextField(RawField):\n",
    "    vocab_cls = Vocab\n",
    "    # Dictionary mapping PyTorch tensor dtypes to the appropriate Python\n",
    "    # numeric type.\n",
    "    dtypes = {\n",
    "        torch.float32: float,\n",
    "        torch.float: float,\n",
    "        torch.float64: float,\n",
    "        torch.double: float,\n",
    "        torch.float16: float,\n",
    "        torch.half: float,\n",
    "\n",
    "        torch.uint8: int,\n",
    "        torch.int8: int,\n",
    "        torch.int16: int,\n",
    "        torch.short: int,\n",
    "        torch.int32: int,\n",
    "        torch.int: int,\n",
    "        torch.int64: int,\n",
    "        torch.long: int,\n",
    "    }\n",
    "    punctuations = [\"''\", \"'\", \"``\", \"`\", \"-LRB-\", \"-RRB-\", \"-LCB-\", \"-RCB-\", \\\n",
    "                    \".\", \"?\", \"!\", \",\", \":\", \"-\", \"--\", \"...\", \";\"] # 截断符号\n",
    "\n",
    "    def __init__(self, use_vocab=True, init_token=None, eos_token=None, fix_length=None, dtype=torch.long,\n",
    "                 preprocessing=None, postprocessing=None, lower=False, tokenize=(lambda s: s.split()),\n",
    "                 remove_punctuation=False, include_lengths=False, batch_first=True, pad_token=\"<pad>\",\n",
    "                 unk_token=\"<unk>\", pad_first=False, truncate_first=False, vectors=None, nopoints=True):\n",
    "        self.use_vocab = use_vocab\n",
    "        self.init_token = init_token\n",
    "        self.eos_token = eos_token\n",
    "        self.fix_length = fix_length # 无固定长度\n",
    "        self.dtype = dtype\n",
    "        self.lower = lower # 全都小写\n",
    "        self.tokenize = get_tokenizer(tokenize) # tokenzie直接返回spacy的lambda函数\n",
    "        self.remove_punctuation = remove_punctuation # 标点符号\n",
    "        self.include_lengths = include_lengths # 训练里面是否包含长度\n",
    "        self.batch_first = batch_first\n",
    "        self.pad_token = pad_token\n",
    "        self.unk_token = unk_token\n",
    "        self.pad_first = pad_first # pad放在前面还是后面\n",
    "        self.truncate_first = truncate_first # 从前面截断还是后面截断\n",
    "        self.vocab = None\n",
    "        self.vectors = vectors #TODO: ??\n",
    "        if nopoints:\n",
    "            self.punctuations.append(\"..\")\n",
    "        # 这里的数据形式是被pad包含着的bos还有eos\n",
    "        super(TextField, self).__init__(preprocessing, postprocessing)\n",
    "    \n",
    "    def preprocess(self, x):\n",
    "        \"\"\"\"分词\"\"\"\n",
    "        if six.PY2 and isinstance(x, six.string_types) and not isinstance(x, six.text_type):\n",
    "            x = six.text_type(x, encoding='utf-8') # 兼容Python2和Python3\n",
    "        if self.lower:\n",
    "            x = six.text_type.lower(x)\n",
    "        x = self.tokenize(x.rstrip('\\n')) # 删除字符尾巴指定字符\n",
    "        if self.remove_punctuation:\n",
    "            x = [w for w in x if w not in self.punctuations]\n",
    "        if self.preprocessing is not None:\n",
    "            return self.preprocessing(x)\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def process(self, batch, device=None):\n",
    "        padded = self.pad(batch)\n",
    "        tensor = self.numericalize(padded, device=device)\n",
    "        return tensor\n",
    "\n",
    "    def build_vocab(self, *args, **kwargs):\n",
    "        counter = Counter()\n",
    "        sources = []\n",
    "        for arg in args:\n",
    "            if isinstance(arg, Dataset):\n",
    "                sources += [getattr(arg, name) for name, field in arg.fields.items() if field is self]\n",
    "            else:\n",
    "                sources.append(arg)\n",
    "\n",
    "        for data in sources:\n",
    "            for x in data:\n",
    "                x = self.preprocess(x)\n",
    "                try:\n",
    "                    counter.update(x)\n",
    "                except TypeError:\n",
    "                    counter.update(chain.from_iterable(x))\n",
    "\n",
    "        specials = list(OrderedDict.fromkeys([\n",
    "            tok for tok in [self.unk_token, self.pad_token, self.init_token,\n",
    "                            self.eos_token]\n",
    "            if tok is not None]))\n",
    "        # 4个特殊字符放在开头\n",
    "        self.vocab = self.vocab_cls(counter, specials=specials, **kwargs)\n",
    "\n",
    "    def pad(self, minibatch):\n",
    "        \"\"\"Pad a batch of examples using this field.\n",
    "        Pads to self.fix_length if provided, otherwise pads to the length of\n",
    "        the longest example in the batch. Prepends self.init_token and appends\n",
    "        self.eos_token if those attributes are not None. Returns a tuple of the\n",
    "        padded list and a list containing lengths of each example if\n",
    "        `self.include_lengths` is `True`, else just\n",
    "        returns the padded list.\n",
    "        \"\"\"\n",
    "        minibatch = list(minibatch)\n",
    "        if self.fix_length is None:\n",
    "            max_len = max(len(x) for x in minibatch)\n",
    "        else:\n",
    "            max_len = self.fix_length + (\n",
    "                self.init_token, self.eos_token).count(None) - 2\n",
    "        padded, lengths = [], []\n",
    "        for x in minibatch:\n",
    "            if self.pad_first:\n",
    "                padded.append(\n",
    "                    [self.pad_token] * max(0, max_len - len(x)) +\n",
    "                    ([] if self.init_token is None else [self.init_token]) +\n",
    "                    list(x[-max_len:] if self.truncate_first else x[:max_len]) +\n",
    "                    ([] if self.eos_token is None else [self.eos_token]))\n",
    "            else:\n",
    "                padded.append(\n",
    "                    ([] if self.init_token is None else [self.init_token]) +\n",
    "                    list(x[-max_len:] if self.truncate_first else x[:max_len]) +\n",
    "                    ([] if self.eos_token is None else [self.eos_token]) +\n",
    "                    [self.pad_token] * max(0, max_len - len(x)))\n",
    "            lengths.append(len(padded[-1]) - max(0, max_len - len(x)))\n",
    "        if self.include_lengths:\n",
    "            return padded, lengths\n",
    "        return padded\n",
    "\n",
    "    def numericalize(self, arr, device=None):\n",
    "        \"\"\"Turn a batch of examples that use this field into a list of Variables.\n",
    "        If the field has include_lengths=True, a tensor of lengths will be\n",
    "        included in the return value.\n",
    "        Arguments:\n",
    "            arr (List[List[str]], or tuple of (List[List[str]], List[int])):\n",
    "                List of tokenized and padded examples, or tuple of List of\n",
    "                tokenized and padded examples and List of lengths of each\n",
    "                example if self.include_lengths is True.\n",
    "            device (str or torch.device): A string or instance of `torch.device`\n",
    "                specifying which device the Variables are going to be created on.\n",
    "                If left as default, the tensors will be created on cpu. Default: None.\n",
    "        \"\"\"\n",
    "        if self.include_lengths and not isinstance(arr, tuple):\n",
    "            raise ValueError(\"Field has include_lengths set to True, but \"\n",
    "                             \"input data is not a tuple of \"\n",
    "                             \"(data batch, batch lengths).\")\n",
    "        if isinstance(arr, tuple):\n",
    "            arr, lengths = arr\n",
    "            lengths = torch.tensor(lengths, dtype=self.dtype, device=device)\n",
    "\n",
    "        if self.use_vocab:\n",
    "            arr = [[self.vocab.stoi[x] for x in ex] for ex in arr]\n",
    "\n",
    "            if self.postprocessing is not None:\n",
    "                arr = self.postprocessing(arr, self.vocab)\n",
    "                \n",
    "            var = torch.tensor(arr, dtype=self.dtype, device=device)\n",
    "        else: # 下面的是用词向量处理\n",
    "            if self.vectors:\n",
    "                arr = [[self.vectors[x] for x in ex] for ex in arr]\n",
    "            if self.dtype not in self.dtypes:\n",
    "                raise ValueError(\n",
    "                    \"Specified Field dtype {} can not be used with \"\n",
    "                    \"use_vocab=False because we do not know how to numericalize it. \"\n",
    "                    \"Please raise an issue at \"\n",
    "                    \"https://github.com/pytorch/text/issues\".format(self.dtype))\n",
    "            numericalization_func = self.dtypes[self.dtype]\n",
    "            # It doesn't make sense to explictly coerce to a numeric type if\n",
    "            # the data is sequential, since it's unclear how to coerce padding tokens\n",
    "            # to a numeric type.\n",
    "            arr = [numericalization_func(x) if isinstance(x, six.string_types)\n",
    "                   else x for x in arr]\n",
    "\n",
    "            if self.postprocessing is not None:\n",
    "                arr = self.postprocessing(arr, None)\n",
    "\n",
    "            var = torch.cat([torch.cat([a.unsqueeze(0) for a in ar]).unsqueeze(0) for ar in arr])\n",
    "\n",
    "        # var = torch.tensor(arr, dtype=self.dtype, device=device)\n",
    "        if not self.batch_first:\n",
    "            var.t_()\n",
    "        var = var.contiguous()\n",
    "\n",
    "        if self.include_lengths:\n",
    "            return var, lengths\n",
    "        return var\n",
    "\n",
    "    def decode(self, word_idxs, join_words=True):\n",
    "        if isinstance(word_idxs, list) and len(word_idxs) == 0:\n",
    "            return self.decode([word_idxs, ], join_words)[0]\n",
    "        if isinstance(word_idxs, list) and isinstance(word_idxs[0], int):\n",
    "            return self.decode([word_idxs, ], join_words)[0]\n",
    "        elif isinstance(word_idxs, np.ndarray) and word_idxs.ndim == 1:\n",
    "            return self.decode(word_idxs.reshape((1, -1)), join_words)[0]\n",
    "        elif isinstance(word_idxs, torch.Tensor) and word_idxs.ndimension() == 1:\n",
    "            return self.decode(word_idxs.unsqueeze(0), join_words)[0]\n",
    "\n",
    "        captions = []\n",
    "        for wis in word_idxs:\n",
    "            caption = []\n",
    "            for wi in wis:\n",
    "                word = self.vocab.itos[int(wi)]\n",
    "                if word == self.eos_token:\n",
    "                    break\n",
    "                caption.append(word)\n",
    "            if join_words:\n",
    "                caption = ' '.join(caption)\n",
    "            captions.append(caption)\n",
    "        return captions"
>>>>>>> e6e60c720fa90393db271e3e4afc07a0a59acfc5
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_field = TextField(init_token='<bos>', eos_token='<eos>', lower=True, tokenize='spacy', remove_punctuation=True, nopoints=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_field.vocab = pickle.load(open('vocab.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
>>>>>>> e6e60c720fa90393db271e3e4afc07a0a59acfc5
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "['h',\n",
       " 'e',\n",
       " 'l',\n",
       " 'l',\n",
       " 'o',\n",
       " ' ',\n",
       " 'w',\n",
       " 'o',\n",
       " 'r',\n",
       " 'l',\n",
       " 'd',\n",
       " '!',\n",
       " '!',\n",
       " '!',\n",
       " 'h',\n",
       " 'e',\n",
       " 'l',\n",
       " 'l',\n",
       " 'o',\n",
       " ' ',\n",
       " 'w',\n",
       " 'o',\n",
       " 'r',\n",
       " 'l',\n",
       " 'd',\n",
       " '!',\n",
       " '!',\n",
       " '!',\n",
       " 'h',\n",
       " 'e',\n",
       " 'l',\n",
       " 'l',\n",
       " 'o',\n",
       " ' ',\n",
       " 'w',\n",
       " 'o',\n",
       " 'r',\n",
       " 'l',\n",
       " 'd',\n",
       " '!',\n",
       " '!',\n",
       " '!',\n",
       " 'h',\n",
       " 'e',\n",
       " 'l',\n",
       " 'l',\n",
       " 'o',\n",
       " ' ',\n",
       " 'w',\n",
       " 'o',\n",
       " 'r',\n",
       " 'l',\n",
       " 'd',\n",
       " '!',\n",
       " '!',\n",
       " '!',\n",
       " 'h',\n",
       " 'e',\n",
       " 'l',\n",
       " 'l',\n",
       " 'o',\n",
       " ' ',\n",
       " 'w',\n",
       " 'o',\n",
       " 'r',\n",
       " 'l',\n",
       " 'd',\n",
       " '!',\n",
       " '!',\n",
       " '!']"
      ]
     },
     "execution_count": 5,
=======
       "76"
      ]
     },
     "execution_count": 39,
>>>>>>> e6e60c720fa90393db271e3e4afc07a0a59acfc5
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "list(itertools.chain(*aa))"
=======
    "len(text_field.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = torch.rand(12, 100) * 75\n",
    "aa = aa.ceil()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[68., 19., 44.,  ..., 25.,  5.,  6.],\n",
       "        [56.,  9., 75.,  ..., 33., 63., 39.],\n",
       "        [39., 41.,  7.,  ..., 63., 56., 33.],\n",
       "        ...,\n",
       "        [26., 57., 32.,  ..., 70., 62., 53.],\n",
       "        [ 1., 35., 15.,  ..., 11., 12.,  1.],\n",
       "        [59., 64., 46.,  ..., 70., 73., 48.]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.003973960876464844,)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time1 = time.time()\n",
    "text_field.decode(aa)\n",
    "time2 = time.time()\n",
    "time2 - time1, "
>>>>>>> e6e60c720fa90393db271e3e4afc07a0a59acfc5
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
